import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import re
from matplotlib import font_manager, rc 

# í•œê¸€ì¶œë ¥ìœ„í•œ í°íŠ¸
font_path = "malgun.ttf" # ì‚¬ìš©í•  í°íŠ¸ëª… ê²½ë¡œ ì‚½ì…
font = font_manager.FontProperties(fname = font_path).get_name()
rc('font', family = font)

# 1. ë°ì´í„° ë¡œë“œ + ì…”í”Œ
df = pd.read_csv("val_split.csv").dropna()
df = df.sample(frac=1, random_state=42).reset_index(drop=True)

# ë¼ë²¨ ì¸ì½”ë” ë¶ˆëŸ¬ì˜¤ê¸°
with open("kc_model_merge/kc_label_encoder_merge.pkl", "rb") as f:
    le = pickle.load(f)
df["label"] = le.transform(df["target"])

# valë§Œ ë¶„ë¦¬ (ì „ì²´ 20%)
val_size = int(len(df))
val_df = df[:val_size]

# í† í¬ë‚˜ì´ì € + ëª¨ë¸ ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained("kc_model_merge")
model = AutoModelForSequenceClassification.from_pretrained("kc_model_merge")

# Dataset ì •ì˜
class ProductDataset(Dataset):
    def __init__(self, texts, labels):
        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=64)
        self.labels = labels

    def __getitem__(self, idx):
        item = {k: torch.tensor(self.encodings[k][idx]) for k in self.encodings}
        item["labels"] = torch.tensor(self.labels[idx], dtype=torch.long)
        return item

    def __len__(self):
        return len(self.labels)

val_dataset = ProductDataset(val_df["input"].tolist(), val_df["label"].tolist())
val_loader = DataLoader(val_dataset, batch_size=8)

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

# í‰ê°€
y_true, y_pred = [], []
with torch.no_grad():
    for batch in val_loader:
        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"].to(device)

        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        preds = torch.argmax(outputs.logits, dim=1)

        y_true.extend(labels.cpu().numpy())
        y_pred.extend(preds.cpu().numpy())

# ë¦¬í¬íŠ¸ ì¶œë ¥
print("\nğŸ“Š Classification Report:")
print(classification_report(
    y_true, y_pred,
    labels=list(range(len(le.classes_))),
    target_names=le.classes_,
    zero_division=0
))

# Confusion Matrix ì‹œê°í™”
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.tight_layout()
plt.savefig("confusion_matrix_val.png")
plt.show()

# ì˜¤ë¶„ë¥˜ ì¸ë±ìŠ¤ ì°¾ê¸°
mismatched_indices = [i for i, (true, pred) in enumerate(zip(y_true, y_pred)) if true != pred]

# ì˜¤ë¶„ë¥˜ ë°ì´í„° ì¶”ì¶œ
misclassified_df = val_df.iloc[mismatched_indices].copy()
misclassified_df["ì˜ˆì¸¡"] = [le.inverse_transform([p])[0] for p in [y_pred[i] for i in mismatched_indices]]
misclassified_df["ì‹¤ì œ"] = [le.inverse_transform([t])[0] for t in [y_true[i] for i in mismatched_indices]]

# í•„ìš”í•œ ì—´ë§Œ í¬í•¨í•˜ì—¬ JSON ë³€í™˜
misclassified_json = misclassified_df[["input", "cleaned_input", "ì‹¤ì œ", "ì˜ˆì¸¡"]].to_dict(orient="records")

import json
with open("misclassified_samples.json", "w", encoding="utf-8") as f:
    json.dump(misclassified_json, f, indent=2, ensure_ascii=False)
